#' @import igraph Formula foreach maxLik
NULL

#' genData create a list of igraph objects. The vertices of each graph containts properties of variable y and variables x which are generated by social interaction model. Mathematically, Y = X \\beta + WX \\theta + WY \\lambda + e 
#' @name genData
#' @aliases genData
#' @title genData
#' @param network_size A vector of the size of networks
#' @param beta Own effect
#' @param theta Contextual Effect
#' @param lambda Spillover Effect 
#' @param degree_dist value of possible degree
#' @param degree_prob probability distribution of the degree
#' @return value A list of igraph object
#' @author TszKin Julian Chan \email{ctszkin@@gmail.com}
#' @examples \dontrun{  
#'   graph = genData(network_size = c(50,50),
#'                   beta = (1:3)*10, 
#'                   theta=(1:3)*10, 
#'                   lambda=0.3, 
#'                   degree_dist=2:3,
#'                   degree_prob=c(0.5,0.5) )
#'   socInt(f=y ~ x1 + x2 + x3 | x1 + x2 + x3, graph)
#' }
#' @export
genData = Vectorize(function(network_size=50, beta=1:3, theta=beta, lambda=0.3, degree_dist=1:5, degree_prob=rep(1/length(degree_dist),length(degree_dist))){
  stopifnot(length(beta)==length(theta))
  k = length(beta)
  x = matrix(rnorm(network_size*k),network_size,k)
  colnames(x) = paste0("x",seq(k))

  while (TRUE){
    degree = sample(degree_dist, network_size, replace=TRUE, prob=degree_prob)
    if (sum(degree) %% 2 == 0) break
  }

  g = degree.sequence.game(degree, method="vl")
  D = as.matrix( get.adjacency(g))
  W =  generateWeighting(D)

  y = solve( diag(network_size) - lambda * W ) %*% ( x%*% beta + W%*%x%*%theta + rnorm(network_size) )

  for (i in seq(k)){
    g = set.vertex.attribute(g, colnames(x)[i] ,value=x[,i] )
  }
  g = set.vertex.attribute(g, "y" ,value=y )
  g
} ,"network_size", SIMPLIFY = FALSE)

#' Generate weighting matrix from adjacency matrix.   
#' @name generateWeighting
#' @aliases generateWeighting
#' @title generateWeighting
#' @param D a network matrix
#' @return weighting matrix
#' @author TszKin Julian Chan \email{ctszkin@@gmail.com}
#' @export
generateWeighting <- function(D){
  W<-D/rowSums(D)
  W[is.nan(W)]<-0
  W
}


#' Estimate social interaction from a lsit of igraph object
#' @name socInt
#' @aliases socInt
#' @title socInt
#' @param f Formula for the model. The left hand side of the model is the outcome variables, first part of lhs the formula is own effect (X, second part of lhs the formula is the contextual effect (WX), third part of lhs the formula is W2X, and so on. For example y~x1+x2+x3|x1+x2+x3|x2. The variables of the formula are the attributes of the vertices. 
#' @param graph A list of igraph object
#' @param method Method of estimation. Default is "maxLik", 
#' @return value maxLik Object
#' @author TszKin Julian Chan \email{ctszkin@@gmail.com}
#' @examples \dontrun{  
#'   graph = genData(network_size = c(50,50),
#'                   beta = (1:3)*10, 
#'                   theta=(1:3)*10, 
#'                   lambda=0.3, 
#'                   degree_dist=2:3,
#'                   degree_prob=c(0.5,0.5) )
#'   socInt(f=y ~ x1 + x2 + x3 | x1 + x2 + x3, graph)
#' }
#' @export
socInt = function(f, graph, method="maxLik"){
  data_list = lapply(graph, extractDataFromIgraph, f=f)
  y = do.call(c, lapply(data_list, "[[", "y") )
  x = do.call(rbind, lapply(data_list, "[[", "x") )
  wy = do.call(c, lapply(data_list, "[[", "wy") )
  n = sapply(data_list, "[[", "n")
  W = lapply(data_list, "[[", "W")


  out = switch(method,
          maxLik = socInt.maxLik(y=y,x=x,wy=wy,W=W,n=n) 
        )
  out
}

#' Estimate social interaction model with maximum likelihood 
#' @name socInt.maxLik
#' @aliases socInt.maxLik
#' @title socInt.maxLik
#' @param y vector of outcome variables 
#' @param x vector of rhs variables 
#' @param wy vector of weighted peers outcome
#' @param n vector of network sizes
#' @param W A list of network weighting matrix
#' @return value maxLik Object
#' @author TszKin Julian Chan \email{ctszkin@@gmail.com}
#' @export
socInt.maxLik = function(y,x,wy,n,W){
  inital_value = coef(lm.fit(y=y,x=cbind(x,wy)))
  maxLik( socIntLiklihood , 
    method="BFGS",
    start=inital_value, 
    X = x, 
    Y = y,
    WY = wy,
    W_list = W,
    n_vector=n 
  )
}




#' extract data from igraph object using formula
#' @name extractDataFromIgraph
#' @aliases extractDataFromIgraph
#' @title extractDataFromIgraph
#' @param f formula
#' @param graph An igraph object
#' @return A list of data 
#' @author TszKin Julian Chan \email{ctszkin@@gmail.com}
#' @keywords internal 
#' @export

extractDataFromIgraph = function(f, graph){
  f = as.Formula(f)

  D = as.matrix( get.adjacency(graph))
  W =  generateWeighting(D)

  data = data.frame( sapply(list.vertex.attributes(graph), get.vertex.attribute, graph=graph) )

  x_matrix_list = lapply(seq(length(f)[2]), function(i){
      tmp_f = formula(f, lhs=0,rhs=i)
      tmp_f = update(tmp_f, ~.-1)
      out = model.matrix(tmp_f, data)
      if (i > 1 ){
        colnames(out) = paste0("W",i-1,"_",colnames(out))
        for (j in 1:(i-1)){
          out = W %*% out
        }
      }
      out
      # apply(out, 2, demean)
    }
  )

  x = do.call(cbind, x_matrix_list )
  y = model.response(model.frame(f,data))
  wy = W %*% y 
  n = length(y)

  list(y=y,x=x,wy=wy,n=n,W=W)
}

#' extract data from igraph object using formula
#' @name socIntLiklihood
#' @aliases socIntLiklihood
#' @title socIntLiklihood
#' @param par Vector of parameters
#' @param X vector of rhs variables 
#' @param Y vector of outcome variables 
#' @param WY vector of weighted peers outcome
#' @param W_list A list of network weighting matrix
#' @param n_vector vector of network sizes
#' @return value maxLik Object
#' @author TszKin Julian Chan \email{ctszkin@@gmail.com}
#' @keywords internal 
#' @export


socIntLiklihood = function(par, X, Y, WY, W_list, n_vector){
  phi=head(par,-1)
  lambda=tail(par,1)
  
  if (any(sum(abs(lambda))>=1)  ) 
    return(-1e+20)

  log_det_Gamma= 0 
  new_y = NULL

  G = length(n_vector)

  for (i in 1:G){
    log_det_Gamma = log_det_Gamma + determinant(diag(n_vector[i]) - W_list[[i]] * lambda , logarithm=TRUE)$modulus 
  }

  new_y = Y - WY * lambda

  varepsilon = new_y - X %*% phi

  splitted_varepsilon = split(varepsilon, rep(1:G, n_vector))
  loglik_varepsilon = sum(
    sapply(splitted_varepsilon, function(z) {
      -(length(z)-1)/2*log(sum(z^2)/(length(z)-1))
    })
  )

  out = loglik_varepsilon + log_det_Gamma - G * log(1 - sum(lambda))

  # out = -(n-1)/2 * log(sum(varepsilon^2)/(n-1)) + log_det_Gamma - length(data) * log(1 - sum(lambda))
  if (!is.finite(out)){
    out = -1e+20
  }
  out
}




